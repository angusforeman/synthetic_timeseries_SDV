{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Source data\n",
    "- Kaggle Intraday Stock Data Set: https://www.kaggle.com/datasets/borismarjanovic/daily-and-intraday-stock-price-data\n",
    "\n",
    "### Prereqs\n",
    "- Tested with Python 3.10\n",
    "- Assumes a folder which contains CSV data sets that can be concatenated together to make the master training data with multiple stock sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\angusf\\source\\repos\\synth_nonin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set & view the working directory to ensure runtime is executng in expected directory\n",
    "cwd = os.getcwd()\n",
    "print(f\"Current working directory: {cwd}\")\n",
    "os.chdir(\"C:/Users/angusf/source/repos/synth_nonin\") #note the use of forward slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder path to bulk CSV files: C:\\Users\\angusf\\source\\repos\\synth_nonin./KaggleDataSet/5 Min/Stocks/SubSet\n",
      "Number of CSV files found: 15\n",
      "Stock symbol from filename:aapl\n",
      "Stock symbol from filename:ae\n",
      "Stock symbol from filename:alex\n",
      "Stock symbol from filename:asr\n",
      "Stock symbol from filename:bld\n",
      "Stock symbol from filename:cbh\n",
      "Stock symbol from filename:cltl\n",
      "Stock symbol from filename:cuz\n",
      "Stock symbol from filename:ebf\n",
      "Stock symbol from filename:eufl\n",
      "Stock symbol from filename:feye\n",
      "Stock symbol from filename:fve\n",
      "Stock symbol from filename:hayn\n",
      "Stock symbol from filename:hbann\n",
      "Stock symbol from filename:hsgx\n",
      "             Date      Time      Open      High       Low     Close   Volume  \\\n",
      "0      2017-11-17  15:35:00  171.0400  171.0500  170.2500  170.3600  1808907   \n",
      "1      2017-11-17  15:40:00  170.3600  170.4100  170.0600  170.0600   481179   \n",
      "2      2017-11-17  15:45:00  170.0600  170.2900  169.8300  170.2500   580184   \n",
      "3      2017-11-17  15:50:00  170.2600  170.2800  169.9700  169.9700   356061   \n",
      "4      2017-11-17  15:55:00  169.9800  170.1900  169.9300  170.1432   405302   \n",
      "...           ...       ...       ...       ...       ...       ...      ...   \n",
      "13723  2017-12-06  20:10:00    1.9400    1.9400    1.9400    1.9400      100   \n",
      "13724  2017-12-06  20:25:00    1.9406    1.9406    1.9406    1.9406      715   \n",
      "13725  2017-12-06  21:05:00    1.9600    1.9600    1.9600    1.9600      100   \n",
      "13726  2017-12-06  21:15:00    1.9600    1.9600    1.9600    1.9600      100   \n",
      "13727  2017-12-06  21:55:00    1.9200    1.9200    1.9200    1.9200      600   \n",
      "\n",
      "      Symbol     Combineddatetime  \n",
      "0       aapl  2017-11-17 15:35:00  \n",
      "1       aapl  2017-11-17 15:40:00  \n",
      "2       aapl  2017-11-17 15:45:00  \n",
      "3       aapl  2017-11-17 15:50:00  \n",
      "4       aapl  2017-11-17 15:55:00  \n",
      "...      ...                  ...  \n",
      "13723   hsgx  2017-12-06 20:10:00  \n",
      "13724   hsgx  2017-12-06 20:25:00  \n",
      "13725   hsgx  2017-12-06 21:05:00  \n",
      "13726   hsgx  2017-12-06 21:15:00  \n",
      "13727   hsgx  2017-12-06 21:55:00  \n",
      "\n",
      "[13728 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas # pandas used to manipulate dataframes\n",
    "import re # regular expressions used to grab stock name from source data file name\n",
    "\n",
    "# set the path to the folder containing the CSV files\n",
    "folder_path = cwd + './KaggleDataSet/5 Min/Stocks/SubSet' #note the use of forward slashes\n",
    "print(f\"Folder path to bulk CSV files: {folder_path}\")\n",
    "# get a list of all the CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "print(f\"Number of CSV files found: {len(csv_files)}\")\n",
    "\n",
    "# read each CSV file into a separate dataframe and concatenate them together\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    individual_file_df = pandas.read_csv(file_path)\n",
    "\n",
    "    # extract the leftmost characters up to the first dot to use as the stock symbol in the dataframe\n",
    "    # assumes the filename is in the format \"<stocksymbol>.<countrycode>.txt\"\n",
    "    filenamematch = re.match(r'^([^.]*)', file)\n",
    "    if filenamematch:\n",
    "            StockSymbolfromFilename = re.match(r'^([^.]*)', file).group(1) \n",
    "    else:\n",
    "            StockSymbolfromFilename = 'null'\n",
    "\n",
    "    print(f\"Stock symbol from filename:{StockSymbolfromFilename}\")\n",
    "    individual_file_df['Symbol'] = StockSymbolfromFilename      #add a column called \"Symbol\" to the dataframe and populate it with the stock symbol extracted from the filename\n",
    "    individual_file_df.drop(['OpenInt'], axis=1, inplace=True)  #drop the OpenInt column from the dataframe (not needed) axis=1 means drop a column, inplace=True means do it in place rather than returning a copy of the dataframe\n",
    "    individual_file_df['Combineddatetime'] = individual_file_df['Date'] + ' ' + individual_file_df['Time'] #combine the Date and Time columns into a single column called Combinedatetime\n",
    "\n",
    "    df_list.append(individual_file_df) # append the dataframes together\n",
    "master_input_data = pandas.concat(df_list, ignore_index=True) #generate the master list \n",
    "\n",
    "# print the resulting dataframe\n",
    "print(master_input_data)\n",
    "master_input_data.to_csv('master_concatenated_stock_input_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
