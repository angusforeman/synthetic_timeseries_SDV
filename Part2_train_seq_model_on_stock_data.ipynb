{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\angusf\\source\\repos\\synth_nonin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set & view the working directory to ensure runtime is executng in expected directory\n",
    "os.chdir(\"C:/Users/angusf/source/repos/synth_nonin\")\n",
    "cwd = os.getcwd()\n",
    "print(f\"Current working directory: {cwd}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequistes\n",
    "- assumes that a training data set consisting of multiple sequeneces of stock data exists in the working folder \n",
    "- assumes that the training data contains the at least the following rows\n",
    "- `Symbol`: contains the stock symbol\n",
    "- `Date`: (with a specific format as specificed in the regex of the metadata setting block below) \n",
    "- `Time`: (with a specific format as specificed in the regex of the metadata setting block below)\n",
    "- `Combineddatetime`: (with a specific format as specificed in the regex of the metadata setting block below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date      Time     Open   High    Low  Close  Volume Symbol  \\\n",
      "0  2017-11-17  15:35:00  68.5300  68.72  68.38  68.67   79411      a   \n",
      "1  2017-11-17  15:40:00  68.5956  68.69  68.56  68.59   10014      a   \n",
      "2  2017-11-17  15:45:00  68.5700  68.67  68.51  68.62   14182      a   \n",
      "\n",
      "     Combineddatetime  \n",
      "0 2017-11-17 15:35:00  \n",
      "1 2017-11-17 15:40:00  \n",
      "2 2017-11-17 15:45:00  \n",
      "Number of rows in data set: 193284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['a', 'aan', 'aav', 'abb', 'aeb', 'aed', 'aee', 'aeg', 'aegn',\n",
       "       'aeh', 'aehr', 'aeis', 'aek', 'ael', 'aem', 'aemd', 'aeo', 'aep',\n",
       "       'aer', 'aeri', 'aes', 'aet', 'aeti', 'aeua', 'aey', 'aezs', 'afam',\n",
       "       'afb', 'afc', 'afg', 'afge', 'afgh', 'afh', 'afhbl', 'afi', 'afl',\n",
       "       'afmd', 'afsd', 'afsi', 'afsi_a', 'afsi_b', 'afsi_c', 'afsi_d',\n",
       "       'afsi_e', 'afsi_f', 'afss', 'afst', 'aft', 'afty', 'ag', 'agc',\n",
       "       'agco', 'agd', 'agen', 'agfs', 'agfsw', 'agge', 'aggp', 'aggy',\n",
       "       'agi', 'agii', 'agiil', 'agio', 'agle', 'agm-a', 'agm', 'agm_a',\n",
       "       'agm_b', 'agm_c', 'agn', 'agnc', 'agncb', 'agncn', 'agn_a', 'ago',\n",
       "       'ago_b', 'ago_e', 'ago_f', 'agr', 'agro', 'agrx', 'agt', 'agtc',\n",
       "       'agu', 'agx', 'agys', 'ahc', 'ahgp', 'ahh', 'ahl', 'ahl_c',\n",
       "       'ahl_d', 'ahp', 'ahpa', 'ahpau', 'ahpaw', 'ahpi', 'ahp_b', 'aht',\n",
       "       'aht_d', 'aht_f', 'aht_g', 'aht_h', 'aht_i', 'ai', 'aic', 'aieq',\n",
       "       'aif', 'aig-ws', 'aig', 'aimc', 'aimt', 'ain', 'ainc', 'ainv',\n",
       "       'air', 'airg', 'airi', 'airt', 'ait', 'aiv', 'aiv_a', 'aiw', 'aiy',\n",
       "       'aiz', 'ai_b', 'ajg', 'ajrd', 'ajx', 'ajxa', 'akam', 'akao',\n",
       "       'akba', 'akca', 'aker', 'akg', 'ako-a', 'ako-b', 'akp', 'akr',\n",
       "       'akrx', 'aks', 'akts', 'aktx', 'al', 'alb', 'albo', 'alco', 'aldr',\n",
       "       'aldw', 'aldx', 'ale', 'alex', 'alfi', 'alg', 'algn', 'algt',\n",
       "       'alim', 'aljj', 'alk', 'alks', 'all', 'alle', 'allt', 'ally',\n",
       "       'ally_a', 'all_a', 'all_b', 'all_c', 'all_d', 'all_e', 'all_f',\n",
       "       'aln', 'alna', 'alny', 'alo', 'alog', 'alot', 'alpn', 'alp_q',\n",
       "       'alqa', 'alrm', 'alrn', 'alsk', 'alsn', 'alt', 'altr', 'alty',\n",
       "       'alv', 'alx', 'alxn', 'am', 'amag', 'amat', 'amba', 'ambc',\n",
       "       'ambcw', 'ambr', 'amc', 'hall', 'hemv', 'hli'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "file_path = './master_concatenated_stock_input_data.csv'\n",
    "training_data_with_sequences = pandas.read_csv(file_path)\n",
    "training_data_with_sequences['Combineddatetime']= pandas.to_datetime(training_data_with_sequences['Combineddatetime'])\n",
    "print(training_data_with_sequences.head(3))\n",
    "print(f\"Number of rows in data set: {training_data_with_sequences.shape[0]}\") # use shape[0] to get number of rows of training data\n",
    "training_data_with_sequences['Symbol'].unique() # list the unique symbols in the master data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"METADATA_SPEC_VERSION\": \"SINGLE_TABLE_V1\",\n",
       "    \"columns\": {\n",
       "        \"Date\": {\n",
       "            \"sdtype\": \"categorical\"\n",
       "        },\n",
       "        \"Time\": {\n",
       "            \"sdtype\": \"categorical\"\n",
       "        },\n",
       "        \"Open\": {\n",
       "            \"sdtype\": \"numerical\"\n",
       "        },\n",
       "        \"High\": {\n",
       "            \"sdtype\": \"numerical\"\n",
       "        },\n",
       "        \"Low\": {\n",
       "            \"sdtype\": \"numerical\"\n",
       "        },\n",
       "        \"Close\": {\n",
       "            \"sdtype\": \"numerical\"\n",
       "        },\n",
       "        \"Volume\": {\n",
       "            \"sdtype\": \"numerical\"\n",
       "        },\n",
       "        \"Symbol\": {\n",
       "            \"sdtype\": \"categorical\"\n",
       "        },\n",
       "        \"Combineddatetime\": {\n",
       "            \"sdtype\": \"datetime\"\n",
       "        }\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata() # for a sequence we can start by auto detecting the meatadata. \n",
    "metadata.detect_from_dataframe(data=training_data_with_sequences) \n",
    "metadata # inspect the autodected metadata pre updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add constraints to the market value related columns to ensure they are understood to be positive values\n",
    "# Note that at present the PAR Sythesiser is not able to handle constraints, so this is listed here for future proofing or using in non sequence data\n",
    "intraday_stock_value_constraints = {\n",
    "'constraint_class': 'Positive',\n",
    "    'constraint_parameters': {\n",
    "        'column_name': 'Open',\n",
    "        'column_name': 'Close',\n",
    "        'column_name': 'High',\n",
    "        'column_name': 'Low',\n",
    "        'strict': True #enforce that the value is positive on the above named columns\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"sequence_key\": \"Symbol\",\n",
       "    \"sequence_index\": \"Combineddatetime\",\n",
       "    \"METADATA_SPEC_VERSION\": \"SINGLE_TABLE_V1\",\n",
       "    \"columns\": {\n",
       "        \"Date\": {\n",
       "            \"sdtype\": \"datetime\",\n",
       "            \"datetime_format\": \"%Y-%m-%d\"\n",
       "        },\n",
       "        \"Time\": {\n",
       "            \"sdtype\": \"datetime\",\n",
       "            \"datetime_format\": \"%H:%M:%S\"\n",
       "        },\n",
       "        \"Open\": {\n",
       "            \"sdtype\": \"numerical\",\n",
       "            \"computer_representation\": \"Float\"\n",
       "        },\n",
       "        \"High\": {\n",
       "            \"sdtype\": \"numerical\",\n",
       "            \"computer_representation\": \"Float\"\n",
       "        },\n",
       "        \"Low\": {\n",
       "            \"sdtype\": \"numerical\",\n",
       "            \"computer_representation\": \"Float\"\n",
       "        },\n",
       "        \"Close\": {\n",
       "            \"sdtype\": \"numerical\",\n",
       "            \"computer_representation\": \"Float\"\n",
       "        },\n",
       "        \"Volume\": {\n",
       "            \"sdtype\": \"numerical\",\n",
       "            \"computer_representation\": \"Float\"\n",
       "        },\n",
       "        \"Symbol\": {\n",
       "            \"sdtype\": \"id\",\n",
       "            \"regex_format\": \"[a-zA-Z]{4}\"\n",
       "        },\n",
       "        \"Combineddatetime\": {\n",
       "            \"sdtype\": \"datetime\",\n",
       "            \"datetime_format\": \"%Y-%m-%d %H:%M:%S\"\n",
       "        }\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tell SDV that the Symbol column is an ID column etc\n",
    "#note that we are comparing with the data types in the documented stock cymbol example https://colab.research.google.com/drive/1cT4-jFK2Bxe93QudC_CwHq_yVCcNcxal?usp=sharing#scrollTo=yfOLibFfR9JF\n",
    "metadata.update_column(column_name='Symbol', sdtype='id',regex_format='[a-zA-Z]{4}')\n",
    "metadata.update_column(column_name='Date', sdtype='datetime',datetime_format='%Y-%m-%d')\n",
    "metadata.update_column(column_name='Time', sdtype='datetime',datetime_format='%H:%M:%S')\n",
    "metadata.update_column(column_name='Combineddatetime', sdtype='datetime',datetime_format='%Y-%m-%d %H:%M:%S')\n",
    "metadata.update_column(column_name='Open', sdtype='numerical', computer_representation='Float')\n",
    "metadata.update_column(column_name='Close', sdtype='numerical', computer_representation='Float')\n",
    "metadata.update_column(column_name='Low', sdtype='numerical', computer_representation='Float')\n",
    "metadata.update_column(column_name='High', sdtype='numerical', computer_representation='Float')\n",
    "metadata.update_column(column_name='Volume', sdtype='numerical', computer_representation='Float')\n",
    "metadata.set_sequence_key(column_name='Symbol') # tell SDV that the Symbol column is the sequence key upon which sequences repeat\n",
    "metadata.set_sequence_index('Combineddatetime') #The SDV formal documentation shows sytax of `metadata.set_sequence_key(sequence_index='Time')` which causes a error\n",
    "# setting the sequence index to the \"Combineddatetime\" column does not produce time stamps in the series that are precisely following the orignal data set increments . So post work likely needed to fix time series date and time values\n",
    "metadata #inspect the updated metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angusf\\AppData\\Roaming\\Python\\Python310\\site-packages\\sdv\\sequential\\par.py:130: UserWarning: The PARSynthesizer does not yet support constraints. This model will ignore any constraints in the metadata.\n",
      "  warnings.warn(\n",
      "Epoch 80 | Loss 1.3906798362731934: 100%|██████████| 80/80 [37:09<00:00, 27.87s/it]\n"
     ]
    }
   ],
   "source": [
    "from sdv.sequential import PARSynthesizer\n",
    "\n",
    "synthesizer = PARSynthesizer(\n",
    "    metadata,\n",
    "    context_columns=[], # update the columns that list the context columns, e.g. those which wont change between sequence/ #date should probably be a context column\n",
    "    enforce_min_max_values=False, #dont enforce min/max values on the columns as this will restruct the results (unless we want similar ranges)                             \n",
    "    enforce_rounding=True, #round the values to the same specificity as the source data \n",
    "    epochs = 80, # the number of epochs to run the model for\n",
    "    verbose = True, #Print out the loss value per epoch. #The loss values indicate how well the neural network is currently performing, lower values indicating higher quality.                \n",
    "    cuda = False #use the GPU if available\n",
    ")\n",
    "\n",
    "#add the non-zero stock value constraints built earlier to the synthesizer (noting these are currently not supported in the PAR model)\n",
    "synthesizer.add_constraints(constraints=[intraday_stock_value_constraints])\n",
    "\n",
    "synthesizer.fit(training_data_with_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the trained synthesiser to disk for later use without the need to retrain\n",
    "synthesizer.save('IntraDayStockSynthesiser.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
